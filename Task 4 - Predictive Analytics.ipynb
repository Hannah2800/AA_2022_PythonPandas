{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c5f81bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 733481 entries, 0 to 733480\n",
      "Data columns (total 23 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   start_date          733481 non-null  object \n",
      " 1   end_date            733481 non-null  object \n",
      " 2   start_time_hourly   733481 non-null  int64  \n",
      " 3   end_time_hourly     733481 non-null  int64  \n",
      " 4   start_station_id    733481 non-null  int64  \n",
      " 5   end_station_id      733481 non-null  int64  \n",
      " 6   start_latitude      733481 non-null  float64\n",
      " 7   start_longitude     733481 non-null  float64\n",
      " 8   end_latitude        733481 non-null  float64\n",
      " 9   end_longitude       733481 non-null  float64\n",
      " 10  min_temp            733481 non-null  float64\n",
      " 11  max_temp            733481 non-null  float64\n",
      " 12  precip              733481 non-null  float64\n",
      " 13  user_type           733481 non-null  object \n",
      " 14  dayOfWeek           733481 non-null  int64  \n",
      " 15  isWeekend           733481 non-null  bool   \n",
      " 16  season              733481 non-null  object \n",
      " 17  isHoliday           733481 non-null  bool   \n",
      " 18  isRushhour          733481 non-null  bool   \n",
      " 19  tripduration_sec    733481 non-null  int64  \n",
      " 20  numOfRentedBikes    733481 non-null  int64  \n",
      " 21  start_station_name  733481 non-null  object \n",
      " 22  end_station_name    733481 non-null  object \n",
      "dtypes: bool(3), float64(7), int64(7), object(6)\n",
      "memory usage: 114.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# import all necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import datetime\n",
    "#import seaborn as sns\n",
    "#import matplotlib as mlp\n",
    "import matplotlib.pyplot as plt\n",
    "#from datetime import datetime\n",
    "\n",
    "# import dataset\n",
    "dfPhiladelphia = pd.read_csv(\"data/tmp/dfPhiladelphia.csv.zip\")\n",
    "dfPhiladelphia.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080c5d1f",
   "metadata": {},
   "source": [
    "# 4. Predictive Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed39e29",
   "metadata": {},
   "source": [
    "- Since the **total system-level demand in the next hour** is of our interest, the station-dependent demand is not needed in this task.\n",
    "- Our target value is `y = numOfRentedBikes`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6eade3",
   "metadata": {},
   "source": [
    "## 4.1 Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3465f3a0",
   "metadata": {},
   "source": [
    "In this subtask, we will:\n",
    "- Develop a rich set of features that we expect to be correlated with our target\n",
    "- We will justify the selection of features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d2e7bd",
   "metadata": {},
   "source": [
    "### 4.1.1 (Feature Creation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f4161c",
   "metadata": {},
   "source": [
    "### 4.1.2 Justify the selection of features / (Feature evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a6ff01",
   "metadata": {},
   "source": [
    "## 4.2 Model Building & Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f7965f",
   "metadata": {},
   "source": [
    "### 4.1 First Regression (Maybe Lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc9aa26",
   "metadata": {},
   "source": [
    "### 4.2 Second Regression (Maybe Support vector machine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e13cfdf",
   "metadata": {},
   "source": [
    "Splitting data set into training and testing (evaluate)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc517e0",
   "metadata": {},
   "source": [
    "Via support vecotr regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b22bd3",
   "metadata": {},
   "source": [
    "(plotting the regression line (target value) and data) ??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ec8bb5",
   "metadata": {},
   "source": [
    "evaluate performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d26dd70",
   "metadata": {},
   "source": [
    "### 4.3 Artificial Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bd4cd8",
   "metadata": {},
   "source": [
    "- Before running you have to install tensorflow: `pip install tensorflow`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c5c199",
   "metadata": {},
   "source": [
    "#### Building the model with the functional API of Keras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5601ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c9cbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import keras libraries\n",
    "import tensorflow\n",
    "from tensorflow inport keras\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbf9568",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### INTEGRATE HYPERPARAMTERTUNING TIPPS!\n",
    "###### RELU IN EACH LAYER?\n",
    "\n",
    "def build_model(hp):\n",
    "    # Input Layer\n",
    "    inputs = keras.Input(shape=(8,)) # shapesize dependent of input features\n",
    "    \n",
    "    # Hidden Layers\n",
    "    ## First Hidden Layer\n",
    "    dense = layers.Dense(units=hp.Int('hidden_layer_1_units', min_value=32, max_value=256, step=32), activation='relu')\n",
    "    x = dense(inputs)\n",
    "    \n",
    "    ## Possible additional Hidden Layers\n",
    "    for i in range(hp.Int('total_added_hidden_layers', 0, 10)):\n",
    "        x = layers.Dense(units=hp.Int(f'hidden_layers_{i+2}_units', min_value=32, max_value=256, step=32), activation='relu')(x)\n",
    "    \n",
    "    # Output Layer\n",
    "    output = layers.Dense(1, activation='relu')(x)\n",
    "    \n",
    "    # Instantiate the model\n",
    "    model_ann = keras.Model(inputs, output, name='system_level_bike_rental_demand_philadelphia')\n",
    "    \n",
    "    # Compile the model\n",
    "    model_ann.compile(optimizer='Adamax', loss='mean_squared_error') # MAYBE TRY DIFFERENT OPTIMIZER\n",
    "    \n",
    "    return model_ann"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aae2d4c",
   "metadata": {},
   "source": [
    "#### Use hyperparameter tuning to find the best model:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f18665",
   "metadata": {},
   "source": [
    "You need to install keras_tuner first: You can use `pip install keras-tuner`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ce845ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f485a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner\n",
    "from keras_tuner.tuners import Hyperband\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9a62cb",
   "metadata": {},
   "source": [
    "Instantiate a tuner for hyperparametertuning:\n",
    "\n",
    "- We choose the HyperBand Tuner from Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12e54e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = Hyperband(\n",
    "    build_model,\n",
    "    objective = 'val_loss',\n",
    "    max_epochs = 20,\n",
    "    factor = 3,\n",
    "    executions_per_trial = 1,\n",
    "    #directory = os.path.normpath('C:/#######')\n",
    "    project_name = 'kerastuner_LOG',\n",
    "    overwrite = True # deletes old LOG's\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc543400",
   "metadata": {},
   "source": [
    "Show a summary of the search space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f45984e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d81a648",
   "metadata": {},
   "source": [
    "To clear the training outputs after each training step define a callback:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc71d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClearTrainingOutput(keras.callbacks.Callback):\n",
    "  def on_train_end(*args, **kwargs):\n",
    "    IPython.display.clear_output(wait = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1282b3",
   "metadata": {},
   "source": [
    "Hyperparameter Search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1426206",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    validation_data=(x_val,y_val),\n",
    "    callbacks = [ClearTrainingOutput()]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0de966c",
   "metadata": {},
   "source": [
    "Show a summary of the results which presents the best model, the hyperparameters and the metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d787b376",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d87144",
   "metadata": {},
   "source": [
    "Get optimal hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0ce2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_best_hps = tuner.get_best_hyperparameters(num_trials = 1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. \n",
    "The optimal number of units in the first hidden layer is {ann_best_hps.get('hidden_layer_1_units')} \n",
    "and the total number of hidden layers is {ann_best_hps.get('total_added_hidden_layers')+1}.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b132baca",
   "metadata": {},
   "source": [
    "Get the best model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc97ddbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ann = tuner.get_best_models(num_models=1)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f0d8ea",
   "metadata": {},
   "source": [
    "Show a summary of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a122ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ann.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd924ed3",
   "metadata": {},
   "source": [
    "Plot the model as a graph:\n",
    "\n",
    "You need to install pydot and graphivz. You can use: `conda install -c anaconda graphviz`and `conda install -c conda-forge python-graphviz` sequentially and `conda install -c conda-forge pydot`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af96a920",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47d4d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.plot_model(model_ann, 'model_ann_system_level_bike_rental_demand_philadelphia.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d144651e",
   "metadata": {},
   "source": [
    "#### Train the model:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1696bd0",
   "metadata": {},
   "source": [
    "In hyperparameter tuning the model was only trained with 20 epochs because of the performance. So now we continue the training to get a optimal result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fc2d36",
   "metadata": {},
   "source": [
    "Define a callback which stops earlier when their is no further improvement and which avoids overfitting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8814b765",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    patience=50, \n",
    "    restore_best_weights=True \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7677fe12",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ann.fit(x_train, y_train, epochs=500, validation_data=(x_val,y_val), callbacks=[callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec006554",
   "metadata": {},
   "source": [
    "#### Evaluation of the performance of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83488b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ann = model_ann.predict(x_test)\n",
    "\n",
    "# Calculate MAE and RMSE\n",
    "mae_ann = mean_absolute_error(y_test,pred_ann)\n",
    "rmse_ann = mean_squared_error(y_test,pred_ann)**0.5\n",
    "\n",
    "print(\"MAE:\", mae_ann)\n",
    "print(\"RMSE:\", rmse_ann)\n",
    "print(\"Accuracy:\", round((1-(mae_ann/dfPhiladelphia[\"numOfRentedBikes\"].mean()))*100,2), \"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
